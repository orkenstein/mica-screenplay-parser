{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from typing import Tuple, Union\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScriptLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = defaultdict(int)\n",
    "for i, label in enumerate(\"SNCDTEM\"):\n",
    "    label2id[label] = i + 1\n",
    "\n",
    "class ScriptLoader:\n",
    "\n",
    "    def __init__(self, scripts: np.ndarray, features: torch.FloatTensor, labels: torch.IntTensor, \\\n",
    "        batch_size: int, shuffle: bool=False) -> None:\n",
    "        self.scripts = scripts\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return math.ceil(len(self.scripts)/self.batch_size)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            index = np.random.permutation(len(self.scripts))\n",
    "            self.scripts = self.scripts[index]\n",
    "            self.features = self.features[index]\n",
    "            self.labels = self.labels[index]\n",
    "        self.i = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self) -> Tuple[np.ndarray, torch.FloatTensor, torch.IntTensor]:\n",
    "        if self.i < len(self):\n",
    "            batch_index = slice(self.i * self.batch_size, (self.i + 1) * self.batch_size)\n",
    "            batch_scripts = self.scripts[batch_index]\n",
    "            batch_features = self.features[batch_index]\n",
    "            batch_labels = self.labels[batch_index]\n",
    "            return batch_scripts, batch_features, batch_labels\n",
    "        else:\n",
    "            raise StopIteration\n",
    "    \n",
    "def get_dataloaders(results_folder: str, seqlen: int, train_batch_size: int, eval_batch_size: int, \\\n",
    "    device: torch.device) -> Tuple[ScriptLoader, ScriptLoader, ScriptLoader]:\n",
    "    df = pd.read_csv(os.path.join(results_folder, \"seq_{}.csv\".format(seqlen)), index_col=None)\n",
    "    feats_df = pd.read_csv(os.path.join(results_folder, \"feats.csv\"), index_col=0)\n",
    "    features_file = os.path.join(results_folder, \"seq_{}_feats.pt\".format(seqlen))\n",
    "    scripts, features, labels = [], [], []\n",
    "\n",
    "    if os.path.exists(features_file):\n",
    "        features = torch.load(features_file).float()\n",
    "    else:\n",
    "        features = []\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            feature = [feats_df.loc[row[\"line_{}\".format(i + 1)]] for i in range(seqlen)]\n",
    "            features.append(feature)\n",
    "        features = torch.FloatTensor(features)\n",
    "        torch.save(features, features_file)\n",
    "        \n",
    "    scripts = df[[\"line_{}\".format(i + 1) for i in range(seqlen)]].values\n",
    "    labels = df[\"label\"].apply(lambda labelseq: [label2id[label] for label in labelseq])\n",
    "    \n",
    "    scripts = np.array(scripts)\n",
    "    features = features.to(device)\n",
    "    labels = torch.IntTensor(labels).to(device)\n",
    "    print(\"scripts : {}, features = {}, labels = {}\".format(scripts.shape, features.shape, labels.shape))\n",
    "\n",
    "    train_index = (df[\"split\"] == \"train\").values\n",
    "    test_index = (df[\"split\"] == \"test\").values\n",
    "    dev_index = (df[\"split\"] == \"dev\").values\n",
    "    \n",
    "    train_loader = ScriptLoader(scripts[train_index], features[train_index], labels[train_index], train_batch_size, \\\n",
    "        shuffle=True)\n",
    "    test_loader = ScriptLoader(scripts[test_index], features[test_index], labels[test_index], eval_batch_size)\n",
    "    dev_loader = ScriptLoader(scripts[dev_index], features[dev_index], labels[dev_index], eval_batch_size)\n",
    "\n",
    "    return train_loader, test_loader, dev_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scripts : (60048, 10), features = torch.Size([60048, 10, 38]), labels = torch.Size([60048, 10])\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, dev_loader = get_dataloaders(\"/workspace/mica-text-robust-script-parser/results\", 10, \\\n",
    "    64, 256, \"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scripts, features, labels in train_loader:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 7, 4, 4, 3, 7, 4, 4, 3],\n",
       "        [2, 2, 2, 2, 2, 1, 2, 2, 2, 2],\n",
       "        [3, 4, 7, 3, 4, 3, 4, 1, 2, 2],\n",
       "        [3, 4, 4, 4, 1, 2, 2, 2, 3, 4],\n",
       "        [4, 3, 4, 4, 4, 3, 4, 0, 4, 3],\n",
       "        [4, 3, 4, 3, 4, 3, 4, 3, 0, 4],\n",
       "        [2, 3, 4, 4, 0, 2, 3, 4, 4, 4],\n",
       "        [2, 3, 4, 0, 1, 2, 2, 2, 3, 4],\n",
       "        [2, 2, 2, 2, 3, 4, 3, 4, 4, 2],\n",
       "        [3, 4, 3, 7, 4, 2, 3, 7, 4, 3],\n",
       "        [4, 4, 4, 1, 2, 2, 2, 3, 4, 4],\n",
       "        [3, 4, 4, 4, 3, 4, 3, 4, 4, 3],\n",
       "        [2, 2, 3, 6, 4, 4, 4, 4, 2, 3],\n",
       "        [4, 3, 4, 4, 3, 4, 4, 4, 4, 4],\n",
       "        [4, 4, 4, 1, 2, 2, 7, 3, 6, 4],\n",
       "        [4, 6, 4, 2, 3, 4, 1, 2, 2, 1],\n",
       "        [2, 2, 2, 3, 4, 4, 3, 4, 3, 4],\n",
       "        [3, 4, 4, 4, 1, 2, 2, 3, 4, 4],\n",
       "        [3, 4, 3, 4, 3, 4, 4, 3, 4, 4],\n",
       "        [2, 3, 4, 4, 2, 2, 2, 1, 2, 2],\n",
       "        [2, 3, 4, 4, 2, 2, 2, 2, 2, 3],\n",
       "        [4, 2, 2, 2, 2, 2, 2, 2, 0, 3],\n",
       "        [2, 3, 6, 4, 3, 4, 4, 6, 4, 3],\n",
       "        [2, 2, 2, 2, 2, 1, 2, 2, 3, 4],\n",
       "        [2, 2, 3, 4, 4, 3, 4, 1, 2, 2],\n",
       "        [4, 3, 4, 2, 2, 2, 2, 2, 0, 3],\n",
       "        [4, 4, 4, 4, 4, 2, 3, 4, 3, 7],\n",
       "        [4, 2, 2, 3, 4, 4, 2, 2, 3, 4],\n",
       "        [4, 4, 4, 2, 3, 4, 4, 4, 4, 4],\n",
       "        [3, 4, 0, 0, 7, 0, 2, 2, 2, 3],\n",
       "        [4, 4, 4, 4, 2, 3, 4, 3, 4, 2],\n",
       "        [4, 2, 3, 7, 4, 3, 4, 2, 3, 4],\n",
       "        [2, 1, 2, 2, 2, 3, 4, 3, 4, 4],\n",
       "        [2, 2, 3, 4, 4, 4, 3, 4, 2, 3],\n",
       "        [4, 3, 4, 4, 4, 4, 4, 3, 4, 4],\n",
       "        [3, 4, 4, 4, 4, 4, 4, 4, 3, 4],\n",
       "        [2, 3, 4, 3, 4, 0, 2, 3, 4, 4],\n",
       "        [2, 1, 2, 2, 2, 1, 2, 2, 3, 4],\n",
       "        [4, 4, 4, 6, 4, 4, 4, 4, 3, 6],\n",
       "        [4, 0, 0, 0, 3, 4, 4, 4, 4, 4],\n",
       "        [4, 2, 3, 4, 6, 4, 3, 4, 2, 3],\n",
       "        [2, 3, 6, 4, 3, 4, 4, 6, 4, 7],\n",
       "        [2, 2, 0, 3, 4, 4, 3, 4, 4, 4],\n",
       "        [4, 6, 4, 4, 2, 3, 4, 4, 3, 4],\n",
       "        [4, 7, 4, 3, 4, 3, 7, 4, 7, 4],\n",
       "        [3, 4, 3, 4, 3, 4, 4, 2, 2, 2],\n",
       "        [2, 2, 2, 2, 2, 2, 3, 4, 4, 2],\n",
       "        [4, 4, 2, 2, 1, 2, 2, 3, 4, 4],\n",
       "        [2, 0, 3, 6, 6, 4, 2, 3, 4, 2],\n",
       "        [6, 6, 4, 4, 2, 2, 3, 6, 4, 1],\n",
       "        [2, 3, 4, 4, 4, 4, 4, 4, 3, 4],\n",
       "        [3, 4, 4, 4, 4, 4, 4, 6, 4, 4],\n",
       "        [2, 3, 6, 4, 4, 4, 4, 6, 3, 4],\n",
       "        [3, 4, 3, 4, 4, 4, 4, 3, 4, 3],\n",
       "        [4, 2, 3, 4, 4, 4, 2, 2, 2, 3],\n",
       "        [4, 4, 3, 4, 3, 4, 4, 4, 4, 4],\n",
       "        [4, 4, 2, 2, 0, 2, 2, 2, 2, 2],\n",
       "        [3, 4, 4, 3, 4, 3, 4, 2, 2, 2],\n",
       "        [3, 4, 3, 4, 3, 4, 2, 2, 3, 4],\n",
       "        [2, 2, 3, 4, 4, 6, 4, 2, 2, 3],\n",
       "        [4, 4, 3, 4, 3, 4, 4, 4, 4, 4],\n",
       "        [2, 1, 2, 2, 2, 5, 2, 1, 2, 2],\n",
       "        [4, 4, 3, 4, 2, 7, 2, 2, 3, 7],\n",
       "        [2, 2, 7, 2, 7, 2, 2, 3, 4, 4]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 17, 3: 130, 7: 17, 4: 268, 2: 168, 1: 19, 6: 20, 5: 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1/np.bincount(labels.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04752822, 0.04252525, 0.0048094 , 0.00621523, 0.00301485,\n",
       "       0.80797982, 0.04039899, 0.04752822])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r/r.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScriptParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScriptParser(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features: int, n_labels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "        self.feature_size = self.encoder.get_sentence_embedding_dimension() + n_features\n",
    "        self.hidden_size = 256\n",
    "        self.n_labels = n_labels\n",
    "        self.lstm = nn.LSTM(self.feature_size, self.hidden_size, batch_first=True)\n",
    "        self.classifier = nn.Linear(self.hidden_size, self.n_labels)\n",
    "    \n",
    "    def forward(self, scripts: np.ndarray, features: torch.FloatTensor, labels: torch.IntTensor = None) -> \\\n",
    "        Union[torch.LongTensor, Tuple[torch.Tensor, torch.LongTensor]]:\n",
    "        batch_size, seqlen = scripts.shape\n",
    "        device = next(self.parameters()).device\n",
    "        script_embeddings = self.encoder.encode(scripts.flatten(), convert_to_tensor=True, device=device)\\\n",
    "            .reshape(batch_size, seqlen, -1)\n",
    "        input = torch.cat([script_embeddings, features], dim=2)\n",
    "        output, _ = self.lstm(input)\n",
    "        logits = self.classifier(output)\n",
    "        pred = logits.argmax(dim=2)\n",
    "        if labels is None:\n",
    "            return pred\n",
    "        else:\n",
    "            ce_loss = nn.CrossEntropyLoss()\n",
    "            loss = ce_loss(logits.reshape(-1, self.n_labels), labels.flatten())\n",
    "            return loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptparser = ScriptParser(38, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = iter(parameter for name, parameter in scriptparser.named_parameters() if not name.startswith(\"encoder\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"/workspace/mica-text-robust-script-parser/results/data.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>line_no</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44_inch_chest</td>\n",
       "      <td>1</td>\n",
       "      <td>out to wear ... whatever combination - it</td>\n",
       "      <td>D</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44_inch_chest</td>\n",
       "      <td>2</td>\n",
       "      <td>works! - You look superb! ... And your</td>\n",
       "      <td>D</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44_inch_chest</td>\n",
       "      <td>3</td>\n",
       "      <td>underw ear - immac ulate ! 100 % cot ton!</td>\n",
       "      <td>D</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44_inch_chest</td>\n",
       "      <td>4</td>\n",
       "      <td>Dazzlin'!... Not like my pinky grey-y</td>\n",
       "      <td>D</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44_inch_chest</td>\n",
       "      <td>5</td>\n",
       "      <td>things! Nah, you've just got it - good at</td>\n",
       "      <td>D</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie  line_no                                       text label  \\\n",
       "0  44_inch_chest        1  out to wear ... whatever combination - it     D   \n",
       "1  44_inch_chest        2     works! - You look superb! ... And your     D   \n",
       "2  44_inch_chest        3  underw ear - immac ulate ! 100 % cot ton!     D   \n",
       "3  44_inch_chest        4      Dazzlin'!... Not like my pinky grey-y     D   \n",
       "4  44_inch_chest        5  things! Nah, you've just got it - good at     D   \n",
       "\n",
       "  error  \n",
       "0  NONE  \n",
       "1  NONE  \n",
       "2  NONE  \n",
       "3  NONE  \n",
       "4  NONE  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.471180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>251.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>251.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>320.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          line_no\n",
       "count  351.000000\n",
       "mean   256.923077\n",
       "std     16.471180\n",
       "min    233.000000\n",
       "25%    250.000000\n",
       "50%    251.000000\n",
       "75%    251.000000\n",
       "max    320.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.groupby([\"movie\", \"error\"]).agg({\"line_no\": len}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((10, 50), device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb540835b400524f1daf22ad4ba940210e80501f4075f2c1b891870a7ef100c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('parser')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
